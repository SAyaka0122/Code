{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle_x_train_normal.shape (40912, 299, 299, 3)\n",
      "kaggle_y_train_normal.shape (40912,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Activation, Dense\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"#specify GPU\n",
    "\n",
    "image_size_width, image_size_height = (299, 299)\n",
    "\n",
    "#train_normal\n",
    "folder = [\"NORMAL_train\"]\n",
    "x_train_normal = []\n",
    "y_train_normal  = []\n",
    "for index, name in enumerate(folder):\n",
    "    dir = \"./\" + name\n",
    "    files = glob.glob(dir + \"/*.jpeg\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"RGB\")#(\"L\")\n",
    "        image = image.resize((image_size_width, image_size_height))\n",
    "        data = np.asarray(image)\n",
    "        x_train_normal.append(data)\n",
    "        y_train_normal.append(index)\n",
    "\n",
    "x_train_normal  = np.array(x_train_normal )\n",
    "y_train_normal  = np.array(y_train_normal )\n",
    "print('x_train_normal.shape', x_train_normal.shape)\n",
    "print('y_train_normal.shape', y_train_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_normal.shape (250, 299, 299, 3)\n",
      "y_test_normal.shape (250,)\n",
      "x_test_anomaly.shape (750, 299, 299, 3)\n",
      "y_test_anomaly.shape (750,)\n"
     ]
    }
   ],
   "source": [
    "#test_normal\n",
    "folder = [\"NORMAL_test\"]\n",
    "x_test_normal = []\n",
    "y_test_normal  = []\n",
    "for index, name in enumerate(folder):\n",
    "    dir = \"./\" + name\n",
    "    files = glob.glob(dir + \"/*.jpeg\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"RGB\")#(\"L\")\n",
    "        image = image.resize((image_size_width, image_size_height))\n",
    "        data = np.asarray(image)\n",
    "        x_test_normal .append(data)\n",
    "        y_test_normal .append(index)\n",
    "\n",
    "x_test_normal  = np.array(x_test_normal )\n",
    "y_test_normal  = np.array(y_test_normal )\n",
    "print('x_test_normal.shape', x_test_normal.shape)\n",
    "print('y_test_normal.shape', y_test_normal.shape)\n",
    "\n",
    "#test_anomaly\n",
    "folder = [\"CNV_test\", \"DME_test\", \"DRUSEN_test\"]\n",
    "x_test_anomaly = []\n",
    "y_test_anomaly  = []\n",
    "for index, name in enumerate(folder):\n",
    "    dir = \"./\" + name\n",
    "    files = glob.glob(dir + \"/*.jpeg\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"RGB\")#(\"L\")\n",
    "        image = image.resize((image_size_width, image_size_height))\n",
    "        data = np.asarray(image)\n",
    "        x_test_anomaly.append(data)\n",
    "        y_test_anomaly.append(index)\n",
    "\n",
    "x_test_anomaly  = np.array(x_test_anomaly)\n",
    "y_test_anomaly  = np.array(y_test_anomaly)\n",
    "print('x_test_anomaly.shape', x_test_anomaly.shape)\n",
    "print('y_test_anomaly.shape', y_test_anomaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "for j in range(1, 11):\n",
    "    model = load_model(f'model.DenseNet201.ep{j:02}.h5', compile=False)\n",
    "    modelA = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    print('validating model %2d ...' %j)\n",
    "\n",
    "    train_a = modelA.predict(x_train_normal)\n",
    "    test_normalA = modelA.predict(x_test_normal)\n",
    "    test_anomalyA = modelA.predict(x_test_anomaly)\n",
    "    #print('train_a_predict', train_a)\n",
    "    #print('test_normalA', test_normalA)\n",
    "    #print('test_anomalyA', test_anomalyA)\n",
    "\n",
    "    train_a = train_a.reshape((len(train_a),-1))\n",
    "    test_normalA = test_normalA.reshape((len(test_normalA),-1))\n",
    "    test_anomalyA = test_anomalyA.reshape((len(test_anomalyA),-1))\n",
    "    #print('train_a.len', train_a.shape)\n",
    "    #print('test_normalA.len', test_normalA.shape)\n",
    "    #print('test_anomalyA.len', test_anomalyA.shape)\n",
    "\n",
    "    ms = MinMaxScaler()\n",
    "    train_a = ms.fit_transform(train_a)\n",
    "    test_normalA = ms.transform(test_normalA)\n",
    "    test_anomalyA = ms.transform(test_anomalyA)\n",
    "    #print('train_a after ms', train_a)\n",
    "    #print('test_normalA after ms', test_normalA)\n",
    "    #print('test_anomalyA after ms', test_anomalyA)\n",
    "\n",
    "    clf_a = LocalOutlierFactor(n_neighbors=20, novelty = False)\n",
    "    a = clf_a.fit(train_a[:5000])\n",
    "\n",
    "    Z1_A_a = []\n",
    "    for i in range(len(x_test_normal)):\n",
    "        Z1_a = -clf_a._decision_function(test_normalA[[i]]) \n",
    "        Z1_A_a.append(Z1_a)\n",
    "        \n",
    "\n",
    "    Z2_A_a = []\n",
    "    for i in range(len(x_test_anomaly)):\n",
    "        Z2_a = -clf_a._decision_function(test_anomalyA[[i]]) \n",
    "        Z2_A_a.append(Z2_a)\n",
    "        \n",
    "    Z1_A = np.reshape(Z1_A_a, -1)\n",
    "    Z2_A = np.reshape(Z2_A_a, -1)\n",
    "       \n",
    "    y_true = np.zeros(len(Z1_A)+len(Z2_A))\n",
    "    y_true[len(Z1_A):] = 1#0:normal、1：abnormal\n",
    "\n",
    "\n",
    "    # calculate FPR, TPR(, threshold) \n",
    "    fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1_A, Z2_A)), pos_label=1)\n",
    "\n",
    "    # AUC\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    #FPR＠TPR = 1.0\n",
    "    alpha = fpr[np.argmax(tpr)]\n",
    "\n",
    "    max_tnr, max_tpr = 0, 0\n",
    "    for k in range(len(fpr)):\n",
    "        if max_tnr + max_tpr < 1-fpr[k] + tpr[k]:\n",
    "            max_tnr = 1-fpr[k]\n",
    "            max_tpr = tpr[k]\n",
    "            \n",
    "    plt.plot(fpr, tpr, label='(AUC = %.11f)'%(auc))\n",
    "    plt.legend()\n",
    "    plt.title(name + '(ROC)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "        \n",
    "    if auc < 1.0:\n",
    "        print('current AUC is %.11f' %auc)\n",
    "        print('current alpha is %.11f' %alpha)\n",
    "            \n",
    "    else:\n",
    "        print('finishing the validation since AUC reached 1.0')\n",
    "        print('alpha is %.11f' %alpha)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0vviQdc70coK",
    "kE7pdVCT6oa5",
    "-7QnhWy_hZHp"
   ],
   "name": "black_simple.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
